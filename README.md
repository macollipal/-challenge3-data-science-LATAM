# Challenge3-data-science-LATAM Telecom X - Parte 2
Challenge Telecom X: an√°lisis de evasi√≥n de clientes - Parte 2

# Churn de Clientes Telcom X üìà

Este proyecto tiene como finalidad anticipar la p√©rdida de clientes (churn) en una compa√±√≠a de telecomunicaciones mediante el uso de modelos de aprendizaje autom√°tico. Su prop√≥sito es detectar a tiempo qu√© clientes tienen mayor riesgo de abandonar el servicio, permitiendo as√≠ aplicar acciones preventivas para mejorar su retenci√≥n.

---


## üìÑ Tabla de Contenidos

1.  [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
2.  [Etapas An√°lisis y Modelado](#-an√°lisis-y-modelado)
3.  [Resultados Claves](#-resultados-clave)
4.  [Interpretaci√≥n de Resultados](#-reconedaciones-estrategicas)


## Descripci√≥n del Proyecto

En la industria de las telecomunicaciones, la fuga de clientes (Churn) representa un reto permanente. Cada cancelaci√≥n afecta de forma directa tanto a los ingresos como al crecimiento de la compa√±√≠a. Este proyecto busca dar respuesta a este desaf√≠o construyendo un modelo de predicci√≥n capaz de detectar a los clientes con mayor probabilidad de abandonar el servicio, lo que permite a la empresa actuar de manera preventiva.

Las etapas desarrolladas fueron:

* **Recolecci√≥n y Preparaci√≥n de Datos:** Importaci√≥n del dataset, normalizaci√≥n de estructuras complejas, depuraci√≥n de registros y manejo de valores ausentes.

* **An√°lisis Exploratorio de Datos (EDA):** Estudio de la distribuci√≥n de las variables y su conexi√≥n con la probabilidad de Churn.

* **Ingenier√≠a de Caracter√≠sticas:** Generaci√≥n de nuevas m√©tricas relevantes y conversi√≥n de variables categ√≥ricas a num√©ricas mediante One-Hot Encoding.

* **Modelado Predictivo:** Entrenamiento y validaci√≥n de modelos de clasificaci√≥n, incluyendo Regresi√≥n Log√≠stica y Random Forest.

* **Interpretaci√≥n de Resultados:** Determinaci√≥n de los factores con mayor impacto en el Churn para respaldar la toma de decisiones estrat√©gicas.


## Etapas Analisis y Modelado



 **Recolecci√≥n y Preparaci√≥n de Datos**

En esta etapa se obtuvieron los datos desde una API en formato JSON y se cargaron en un DataFrame de Pandas para su an√°lisis. Se aplanaron las estructuras anidadas, transformando diccionarios y listas en columnas planas mediante funciones de normalizaci√≥n. 

Se revisaron y ajustaron los tipos de datos, convirtiendo a formato num√©rico aquellas columnas que estaban como texto y reemplazando separadores decimales. Se identificaron y trataron valores nulos mediante eliminaci√≥n o imputaci√≥n seg√∫n el caso. Finalmente, se renombraron columnas para mejorar la claridad y consistencia en las etapas posteriores del an√°lisis.

El archivo resultante, denominado datos_tratados.csv, es el que se utiliza como base en este proyecto.

 **An√°lisis Exploratorio de Datos (EDA):**

* Se revisaron las primeras filas de la base para entender su estructura.

* Se verificaron los valores faltantes por columna.

* Se analiz√≥ la variable objetivo (churn_1) contando cu√°ntos clientes permanecen y cu√°ntos se fugan, adem√°s de graficarlo en un diagrama circular con porcentajes y cantidades.

* Se calcul√≥ y visualiz√≥ la correlaci√≥n entre variables num√©ricas para detectar posibles relaciones.

* Gr√°fico principal EDA

![Proporci√≥n de clientes por Churn](imagenes/churn_pie.png)

 **Ingenier√≠a de Caracter√≠sticas:**

1.  Creaci√≥n de nuevas variables

 * Se gener√≥ la columna account_charges_daily dividiendo el cargo mensual por 30, para obtener un valor aproximado de facturaci√≥n diaria por cliente.

 * Esto permiti√≥ analizar el comportamiento del cliente en una escala m√°s granular.

2.  Transformaci√≥n de variables categ√≥ricas

 * Las columnas con valores de tipo texto (como "S√≠"/"No") fueron codificadas num√©ricamente utilizando One-Hot Encoding o conversi√≥n a binario (1/0).

 * Esto asegur√≥ que los algoritmos pudieran procesar estas variables en modelos predictivos.

3.  Tratamiento de la variable objetivo (churn)

 * Se codific√≥ churn como 1 para ‚ÄúFuga‚Äù y 0 para ‚ÄúPermanece‚Äù.

 * Esta codificaci√≥n permiti√≥ que fuera utilizada directamente como variable dependiente en modelos de clasificaci√≥n.

4.  Selecci√≥n de variables relevantes

 * Se identificaron las columnas m√°s influyentes para el an√°lisis y se eliminaron aquellas que no aportaban valor o que eran redundantes.

## Resultados Claves

## ü§ñ Modelado Predictivo

**An√°lisis del Modelo Predictivo:**

Se entrenaron y evaluaron dos algoritmos para predecir la variable objetivo `churn_1`: **Regresi√≥n Log√≠stica** y **Random Forest**.

**Regresi√≥n Log√≠stica:** modelo lineal que permite interpretar el peso de cada variable en la probabilidad de fuga. Present√≥ buen rendimiento para identificar clientes que permanecen, pero menor sensibilidad para detectar casos de fuga.

**Random Forest:** modelo de ensamble basado en m√∫ltiples √°rboles de decisi√≥n. Obtuvo un mejor equilibrio entre clases, detectando m√°s clientes en riesgo de fuga sin sacrificar demasiado la precisi√≥n global.

Los datos se dividieron en **entrenamiento** y **prueba**, y se evalu√≥ el rendimiento mediante **accuracy** y **matriz de confusi√≥n**.

| Modelo               | Accuracy | Sensibilidad (Recall Fuga) | Precisi√≥n (Precision Fuga) | Observaciones |
|----------------------|----------|----------------------------|----------------------------|--------------|
| Regresi√≥n Log√≠stica  | 0.80     | 0.65                       | 0.68                       | M√°s interpretable, menor capacidad para detectar fugas. |
| Random Forest        | 0.83     | 0.72                       | 0.70                       | Mejor equilibrio entre clases, mayor detecci√≥n de fugas. |


**Conclusi√≥n:** el **Random Forest** se adapta mejor a este problema debido a su capacidad para manejar relaciones no lineales y variables categ√≥ricas. Se recomienda optimizar hiperpar√°metros y aplicar t√©cnicas de balanceo de clases (como **SMOTE** o ponderaci√≥n de clases) para mejorar la detecci√≥n de churn.


## Interpretaci√≥n de Resultados 

 > El gr√°fico muestra **correlaciones ‚â• 0.2** (o ‚â§ -0.2) con la variable objetivo `Churn_Yes` (`churn_1`).

### üìä Correlaci√≥n con `Churn_Yes` (variable objetivo)

En las visualizacions de abajo las relaciones entre variables num√©ricas y la variable objetivo churn_1. Resalta factores que aumentan la probabilidad de fuga (ej. fibra √≥ptica, pago con cheque electr√≥nico) y factores que la reducen (ej. contrato de dos a√±os, mayor antig√ºedad).

| üìå Variable | üìà Correlaci√≥n | üí° Interpretaci√≥n |
|-------------|---------------|-------------------|
| **internet.InternetService_Fiber optic** | `+0.31` | Clientes con fibra √≥ptica tienen **mayor probabilidad de churn**. Puede estar relacionado al costo o a la competitividad. |
| **account.PaymentMethod_Electronic check** | `+0.30` | Pagos por cheque electr√≥nico est√°n asociados a m√°s churn ‚Äì quiz√°s por perfil de cliente menos fidelizado. |
| **account.Contract_Two year** | `-0.30` | Contratos de 2 a√±os reducen el churn (clientes m√°s comprometidos o con beneficios). |
| **customer.tenure** | `-0.35` | Cuanto mayor el tiempo como cliente, menor la probabilidad de churn ‚Äì esperado. |
| **internet.InternetService_No** | `-0.23` | Quienes **no usan internet** tienden a churnar menos ‚Äì posiblemente perfiles m√°s estables (adultos mayores, menos digitales). |

<img src="imagenes/correlacion_churn.png" alt="An√°lisis del heatmap de correlaci√≥n" width="60%"/>


## Comparacion de modelos entrenados

### üìà Interpretaci√≥n de Resultados

Al comparar los modelos entrenados:

- **Regresi√≥n Log√≠stica:**  
  Buen rendimiento general (accuracy = 0.80) para identificar clientes que permanecen, pero menor capacidad para detectar fugas (recall = 0.65). Esto implica que varios clientes en riesgo no son detectados, lo que puede limitar las estrategias de retenci√≥n.  

  ![Matriz de confusi√≥n - Regresi√≥n Log√≠stica](imagenes/ConfusionMatrix-LR.png)

- **Random Forest:**  
  Mejor equilibrio entre precisi√≥n y sensibilidad, con accuracy de 0.83 y recall = 0.72 para la clase ‚ÄúFuga‚Äù. Esto significa que detecta m√°s clientes en riesgo y reduce falsos negativos, aunque a√∫n puede optimizarse con ajustes de hiperpar√°metros y balanceo de clases.  

  ![Matriz de confusi√≥n - Random Forest](imagenes/ConfusionMatrix-RF.png)

**Conclusi√≥n general:**  
El **Random Forest** se adapta mejor a este problema, ya que mejora la detecci√≥n de churn manteniendo un rendimiento estable. La **Regresi√≥n Log√≠stica** sigue siendo √∫til como modelo interpretable de referencia, pero menos efectiva para identificar clientes en riesgo.

## üìù Instrucciones para ejecutar el cuaderno

1. **Abrir el archivo** `challenge3_data_science_LATAM.ipynb` en Google Colab o Jupyter Notebook.  
2. Asegurarse de tener en la misma carpeta el archivo **`datos_tratados.csv`**, ya que el cuaderno lo utiliza como base para el an√°lisis y modelado.  
3. **Ejecutar las celdas en orden**, desde la carga de datos hasta el modelado.  
4. Verificar que est√©n instaladas las librer√≠as necesarias: Pandas, NumPy, Matplotlib, Seaborn y Scikit-learn.  
5. El cuaderno mostrar√° los resultados del an√°lisis, gr√°ficos y m√©tricas de los modelos.  
